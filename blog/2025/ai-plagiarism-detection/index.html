<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*fE0TNrEdUbBkwwX-"><figcaption>Image From Turnitin</figcaption></figure> <p>By: Chloe Poon</p> <p>Additional Contributions: Sahana Narayan</p> <p>In Wichita, Texas, Midwestern State University student Jessica Zimny was assigned to write a short post for her political science class. She turned her post in, which was then scanned by an AI detector. The scan concluded that the post was sixty-seven percent written by artificial intelligence, and she received a zero. However, the scan was wrong. Zimny had not used AI.</p> <p>Enter AI writing detectors. With the rise of large language models like ChatGPT producing human-like writing, the education system has had to learn to fight back. You may have heard of Turnitin, a widely used platform by schools to detect AI writing. While Turnitin and other AI detectors have been proven to catch cheating in academia, they have a surprising rate of false positives.</p> <p>A “false positive” means that a fully human-generated text was identified as AI-generated. On their website, <a href="https://www.turnitin.com/blog/understanding-false-positives-within-our-ai-writing-detection-capabilities" rel="external nofollow noopener" target="_blank">Turnitin</a> maintains that its detectors do not “make a determination of misconduct.” In other words, a more accurate implication of a false positive would be an indication of generic writing, rather than evidence of AI use.</p> <p><a href="https://www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations" rel="external nofollow noopener" target="_blank"><em>Bloomberg Businessweek</em> performed a test</a> with 500 random Texas A&amp;M authentic college essay submissions written before ChatGPT was released (Davalos). Through two popular AI detection systems, 1% to 2% of essays were falsely identified as AI-written. Some papers were flagged as 100% written by AI while others only had sections flagged. Now, is this a random occurrence? Not quite.</p> <p>When <a href="https://www.washingtonpost.com/technology/2023/04/01/chatgpt-cheating-detection-turnitin/" rel="external nofollow noopener" target="_blank">the <em>Washington Post</em> spoke to Turnitin’s Vice President Eric Wang</a>, Wang claimed that Turnitin detects AI in writing that is “too consistently average” (Fowler). Large language models like ChatGPT create sentences using real human writing as examples. If you type on an iPhone, you probably see a bar that auto-completes your writing. Seen below in blue.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*DW0SeQNVepCGVTHW"></figure> <p>It boils down to statistics in the question: “After this word, what is most likely the next word in the sentence?” In this context, the result would be labeled “generic writing” since it is based on a generic sample of word combinations.</p> <p>Ultimately, “AI writing is the most probable subset of human writing,” says Wang. This is what the AI detector looks for.</p> <p>Moreover, AI detectors can prove difficult for non-native English speakers. A <a href="https://arxiv.org/pdf/2304.02819" rel="external nofollow noopener" target="_blank">2023 study done by Stanford University</a> focused on measuring bias against non-native speakers (Liang). AI detectors were twice as likely to be critical of a non-native speaker’s essay versus a native speaker’s. This bias does not only apply to non-native English speakers. Many on the neurodivergent spectrum tend to be also biased against by their writing. This bias has caused blind spots in AI detection to bloom.</p> <p>As a result, many AI detection systems like to identify themselves as more “invitations” for criticism in student writing. However, many schools still treat AI detection as fact, and the unfortunate reality is that AI accusations can lead to much worse punishments. Suspension, expulsion, and other penalties on a record can significantly reduce students’ academic and professional opportunities.</p> <p>Students, like MSU student Jessica Zimny, have been looking for ways to combat this after being accused of using AI (Verma). Despite pleading her case to the department head and even the school dean, Zimny could not prove her innocence. When asked by the <em>Washington Post</em>, Zimny revealed that she resorted to <a href="https://www.washingtonpost.com/technology/2023/08/13/ai-chatgpt-chatbots-college-cheating/" rel="external nofollow noopener" target="_blank">screen-recording</a> herself writing assignments to prepare for the worst case.</p> <p>This dilemma highlights how AI detectors are treated as judges across schools rather than feedback machines. And unfortunately, that leaves students like Jessica Zimny still stuck trying to defend their own words.</p> <p><strong>References</strong></p> <p>Davalos, Jackie, and Leon Yin. “Do AI Detectors Work? Students Face False Cheating Accusations.” <em>Bloomberg.Com</em>, 18 Oct. 2024, <a href="http://www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations." rel="external nofollow noopener" target="_blank">www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations.</a></p> <p>Fowler, Geoffrey. “We Tested a New ChatGPT-Detector for Teachers. It Flagged an Innocent Student.” <em>The Washington Post</em>, 3 Apr. 2023, <a href="http://www.washingtonpost.com/technology/2023/04/01/chatgpt-cheating-detection-turnitin/." rel="external nofollow noopener" target="_blank">www.washingtonpost.com/technology/2023/04/01/chatgpt-cheating-detection-turnitin/.</a></p> <p>Liang, Weixin, et al. “GPT detectors are biased against non-native English writers.” <em>Patterns</em>, vol. 4, no. 7, July 2023, p. 100779, <a href="https://doi.org/10.1016/j.patter.2023.100779." rel="external nofollow noopener" target="_blank">https://doi.org/10.1016/j.patter.2023.100779.</a></p> <p>Verma, Pranshu. “Professors Have a Summer Assignment: Prevent ChatGPT Chaos in the Fall.” <em>The Washington Post</em>, 13 Aug. 2023, <a href="http://www.washingtonpost.com/technology/2023/08/13/ai-chatgpt-chatbots-college-cheating/." rel="external nofollow noopener" target="_blank">www.washingtonpost.com/technology/2023/08/13/ai-chatgpt-chatbots-college-cheating/.</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fc7f50c41c8c" width="1" height="1" alt=""></p> </body></html>