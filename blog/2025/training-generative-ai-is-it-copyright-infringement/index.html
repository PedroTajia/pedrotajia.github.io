<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <figure><img alt="" src="https://cdn-images-1.medium.com/max/797/0*fnjkY1gnqcRl9ICG"><figcaption>Image by Marianas Variety</figcaption></figure> <p>By: Alinda Lau</p> <p>Additional Contributions: Sahana Narayan, Pearl Vishen</p> <p>Many questions on copyright infringement have been emerging as usage of generative AI has become increasingly widespread. However, one question has been particularly recurrent: should companies be allowed to train their AI models on other people’s work without authorization?</p> <p>After being trained on large amounts of data, generative AI becomes capable of creating imitations of the content it was trained on. If a model is trained with large amounts of textual content, such as academic papers and journal articles, then it will generate output text that utilizes patterns from the data it was trained on.</p> <p>Currently, the most well-known generative AI model is OpenAI’s ChatGPT. Given the model’s popularity, OpenAI has become a primary target of copyright infringement lawsuits.</p> <p>In December of 2023, The New York Times filed a lawsuit against Microsoft and OpenAI, accusing them of violating copyright with their “unlawful use of The Times’s work to create artificial intelligence products that compete with it.” After being trained on datasets that included NYT articles, the defendants’ models were able to generate outputs that were highly similar, if not completely identical, to The Times’ original content. In response to NYTimes’ allegations, OpenAI argued that “[t]raining AI models using publicly available internet materials is fair use.”</p> <p>The U.S. Copyright Office defines fair use as “a legal doctrine that promotes freedom of expression by permitting the unlicensed use of copyright-protected works in certain circumstances.” Section 107 of the Copyright Act, an act that protects original works of authorship, provides the following 4 factors to evaluate whether something falls under fair use or not:</p> <ol> <li>“The purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes.”</li> <li>“The nature of the copyrighted work” — whether the copyrighted work reflects creative expression or factual reporting</li> <li>“The amount and substantiality of the portion used in relation to the copyrighted work as a whole.” (In some circumstances, even using a small portion of a copyrighted work can be ruled as not fair use because it was an important part of the work’s essence.)</li> <li>“The effect of the use upon the potential market for or value of the copyrighted work” — whether the instance of unlicensed use harms the market for the original work.</li> </ol> <p>The fourth factor is particularly of concern for the Times as they are concerned that ChatGPT’s verbatim recitation of their content will make people drastically less likely to pay for a subscription to their publication.</p> <p>It is also worth noting that, under the first factor of consideration, unauthorized use of copyright-protected works is far more likely to be considered fair use if the new content uses the original copyright-protected content in a “transformative” way — in a way that adds something new to it.</p> <p>OpenAI leans into this, emphasizing that their main goal — which they claim to have successfully executed for the most part — is for generative AI to produce transformative outputs based on the data it was trained on. Despite The Times’ accusations, OpenAI says that verbatim recitation is “a rare failure of the learning process that [they] are continually making progress on,” not a common occurrence nor the intended use of their technology. They insist that their models are “designed and trained to learn concepts in order to apply them to new problems,” not to simply replicate existing content.</p> <p>With no end date in sight, it is apparent that this case is only the beginning of the clash between journalism and generative AI. Content creators of other specialities, authors and artists, have also filed fair use lawsuits against AI and tech companies. Though the continuous progression of AI technology is exciting, standards for regulation must progress alongside it, or we may find ourselves in a bottomless pit of compounding legal and ethical concerns.</p> <p>References</p> <p>[1] <a href="https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf" rel="external nofollow noopener" target="_blank">https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf</a></p> <p>[2] <a href="https://openai.com/index/openai-and-journalism/" rel="external nofollow noopener" target="_blank">https://openai.com/index/openai-and-journalism/</a></p> <p>[3] <a href="https://www.copyright.gov/fair-use/" rel="external nofollow noopener" target="_blank">https://www.copyright.gov/fair-use/</a></p> <p>[4] <a href="https://www.copyright.gov/title17/92chap1.html#107" rel="external nofollow noopener" target="_blank">https://www.copyright.gov/title17/92chap1.html#107</a></p> <p>[5] <a href="https://openai.com/index/openai-and-journalism/" rel="external nofollow noopener" target="_blank">https://openai.com/index/openai-and-journalism/</a></p> <p>[6] <a href="https://openai.com/index/openai-and-journalism/" rel="external nofollow noopener" target="_blank">https://openai.com/index/openai-and-journalism/</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0ea5c2ad46f7" width="1" height="1" alt=""></p> </body></html>